{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38fad8ed",
   "metadata": {},
   "source": [
    "# Fundamental Data Download and Preparation\n",
    "\n",
    "This notebook is to download the required data from yfinance once for all the interested tickers. Once we have the data, we no longer need to keep going out to the internet and request more data, reducing network load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f94d3140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (0.2.65)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from yfinance) (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from yfinance) (2.3.1)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from yfinance) (2.32.4)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from yfinance) (4.3.8)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from yfinance) (2025.2)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from yfinance) (2.4.6)\n",
      "Requirement already satisfied: peewee>=3.16.2 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from yfinance) (3.18.2)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from yfinance) (4.13.4)\n",
      "Requirement already satisfied: curl_cffi>=0.7 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from yfinance) (0.12.0)\n",
      "Requirement already satisfied: protobuf>=3.19.0 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from yfinance) (6.31.1)\n",
      "Requirement already satisfied: websockets>=13.0 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from yfinance) (14.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (4.14.1)\n",
      "Requirement already satisfied: cffi>=1.12.0 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from curl_cffi>=0.7->yfinance) (1.17.1)\n",
      "Requirement already satisfied: certifi>=2024.2.2 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from curl_cffi>=0.7->yfinance) (2025.7.14)\n",
      "Requirement already satisfied: pycparser in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from requests>=2.31->yfinance) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from requests>=2.31->yfinance) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from requests>=2.31->yfinance) (2.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from pandas) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install yfinance\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07407b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c499e02",
   "metadata": {},
   "source": [
    "## Select tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96f2bf06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found tickers with technical data: ['AAPL', 'ACMR', 'AFRM', 'ALAB', 'AMSC', 'AMZN', 'ANET', 'APH', 'ATAT', 'ATI', 'BK', 'BRK-B', 'CCJ', 'CLS', 'COIN', 'CRCL', 'CRWD', 'C', 'DASH', 'DAVE', 'DOCS', 'FIX', 'FRFHF', 'FUTU', 'GOOGL', 'HEI', 'HOOD', 'IREN', 'JBL', 'JPM', 'KLAC', 'KNSA', 'LIF', 'META', 'MIRM', 'MSFT', 'NET', 'NVDA', 'ONC', 'OUST', 'PLTR', 'PWR', 'RBLX', 'RKLB', 'RMBS', 'RYTM', 'SFM', 'SHOP', 'SNEX', 'SNOW', 'SOFI', 'SYM', 'TBBK', 'TOST', 'TSLA', 'TSM', 'TSSI', 'URBN', 'VEEV', 'VRT', 'WMT', 'XOM', 'ZS']\n",
      "Total tickers found: 63\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get tickers from data folder\n",
    "data_files = [f for f in os.listdir('data') if f.endswith('_stock_data.csv')]\n",
    "tickers = [f.replace('_stock_data.csv', '') for f in data_files]\n",
    "\n",
    "print(f\"Found tickers with technical data: {tickers}\")\n",
    "print(f\"Total tickers found: {len(tickers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2574aff",
   "metadata": {},
   "source": [
    "## For each ticker, download the info and fundamental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7d1a0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing AAPL...\n",
      "‚úÖ Key fundamentals saved to fundamentals/AAPL_key_info.json\n",
      "\n",
      "Processing ACMR...\n",
      "‚úÖ Key fundamentals saved to fundamentals/ACMR_key_info.json\n",
      "\n",
      "Processing AFRM...\n",
      "‚úÖ Key fundamentals saved to fundamentals/AFRM_key_info.json\n",
      "\n",
      "Processing ALAB...\n",
      "‚úÖ Key fundamentals saved to fundamentals/ALAB_key_info.json\n",
      "\n",
      "Processing AMSC...\n",
      "‚úÖ Key fundamentals saved to fundamentals/AMSC_key_info.json\n",
      "\n",
      "Processing AMZN...\n",
      "‚úÖ Key fundamentals saved to fundamentals/AMZN_key_info.json\n",
      "\n",
      "Processing ANET...\n",
      "‚úÖ Key fundamentals saved to fundamentals/ANET_key_info.json\n",
      "\n",
      "Processing APH...\n",
      "‚úÖ Key fundamentals saved to fundamentals/APH_key_info.json\n",
      "\n",
      "Processing ATAT...\n",
      "‚úÖ Key fundamentals saved to fundamentals/ATAT_key_info.json\n",
      "\n",
      "Processing ATI...\n",
      "‚úÖ Key fundamentals saved to fundamentals/ATI_key_info.json\n",
      "\n",
      "Processing BK...\n",
      "‚úÖ Key fundamentals saved to fundamentals/BK_key_info.json\n",
      "\n",
      "Processing BRK-B...\n",
      "‚úÖ Key fundamentals saved to fundamentals/BRK-B_key_info.json\n",
      "\n",
      "Processing CCJ...\n",
      "‚úÖ Key fundamentals saved to fundamentals/CCJ_key_info.json\n",
      "\n",
      "Processing CLS...\n",
      "‚úÖ Key fundamentals saved to fundamentals/CLS_key_info.json\n",
      "\n",
      "Processing COIN...\n",
      "‚úÖ Key fundamentals saved to fundamentals/COIN_key_info.json\n",
      "\n",
      "Processing CRCL...\n",
      "‚úÖ Key fundamentals saved to fundamentals/CRCL_key_info.json\n",
      "\n",
      "Processing CRWD...\n",
      "‚úÖ Key fundamentals saved to fundamentals/CRWD_key_info.json\n",
      "\n",
      "Processing C...\n",
      "‚úÖ Key fundamentals saved to fundamentals/C_key_info.json\n",
      "\n",
      "Processing DASH...\n",
      "‚úÖ Key fundamentals saved to fundamentals/DASH_key_info.json\n",
      "\n",
      "Processing DAVE...\n",
      "‚úÖ Key fundamentals saved to fundamentals/DAVE_key_info.json\n",
      "\n",
      "Processing DOCS...\n",
      "‚úÖ Key fundamentals saved to fundamentals/DOCS_key_info.json\n",
      "\n",
      "Processing FIX...\n",
      "‚úÖ Key fundamentals saved to fundamentals/FIX_key_info.json\n",
      "\n",
      "Processing FRFHF...\n",
      "‚úÖ Key fundamentals saved to fundamentals/FRFHF_key_info.json\n",
      "\n",
      "Processing FUTU...\n",
      "‚úÖ Key fundamentals saved to fundamentals/FUTU_key_info.json\n",
      "\n",
      "Processing GOOGL...\n",
      "‚úÖ Key fundamentals saved to fundamentals/GOOGL_key_info.json\n",
      "\n",
      "Processing HEI...\n",
      "‚úÖ Key fundamentals saved to fundamentals/HEI_key_info.json\n",
      "\n",
      "Processing HOOD...\n",
      "‚úÖ Key fundamentals saved to fundamentals/HOOD_key_info.json\n",
      "\n",
      "Processing IREN...\n",
      "‚úÖ Key fundamentals saved to fundamentals/IREN_key_info.json\n",
      "\n",
      "Processing JBL...\n",
      "‚úÖ Key fundamentals saved to fundamentals/JBL_key_info.json\n",
      "\n",
      "Processing JPM...\n",
      "‚úÖ Key fundamentals saved to fundamentals/JPM_key_info.json\n",
      "\n",
      "Processing KLAC...\n",
      "‚úÖ Key fundamentals saved to fundamentals/KLAC_key_info.json\n",
      "\n",
      "Processing KNSA...\n",
      "‚úÖ Key fundamentals saved to fundamentals/KNSA_key_info.json\n",
      "\n",
      "Processing LIF...\n",
      "‚úÖ Key fundamentals saved to fundamentals/LIF_key_info.json\n",
      "\n",
      "Processing META...\n",
      "‚úÖ Key fundamentals saved to fundamentals/META_key_info.json\n",
      "\n",
      "Processing MIRM...\n",
      "‚úÖ Key fundamentals saved to fundamentals/MIRM_key_info.json\n",
      "\n",
      "Processing MSFT...\n",
      "‚úÖ Key fundamentals saved to fundamentals/MSFT_key_info.json\n",
      "\n",
      "Processing NET...\n",
      "‚úÖ Key fundamentals saved to fundamentals/NET_key_info.json\n",
      "\n",
      "Processing NVDA...\n",
      "‚úÖ Key fundamentals saved to fundamentals/NVDA_key_info.json\n",
      "\n",
      "Processing ONC...\n",
      "‚úÖ Key fundamentals saved to fundamentals/ONC_key_info.json\n",
      "\n",
      "Processing OUST...\n",
      "‚úÖ Key fundamentals saved to fundamentals/OUST_key_info.json\n",
      "\n",
      "Processing PLTR...\n",
      "‚úÖ Key fundamentals saved to fundamentals/PLTR_key_info.json\n",
      "\n",
      "Processing PWR...\n",
      "‚úÖ Key fundamentals saved to fundamentals/PWR_key_info.json\n",
      "\n",
      "Processing RBLX...\n",
      "‚úÖ Key fundamentals saved to fundamentals/RBLX_key_info.json\n",
      "\n",
      "Processing RKLB...\n",
      "‚úÖ Key fundamentals saved to fundamentals/RKLB_key_info.json\n",
      "\n",
      "Processing RMBS...\n",
      "‚úÖ Key fundamentals saved to fundamentals/RMBS_key_info.json\n",
      "\n",
      "Processing RYTM...\n",
      "‚úÖ Key fundamentals saved to fundamentals/RYTM_key_info.json\n",
      "\n",
      "Processing SFM...\n",
      "‚úÖ Key fundamentals saved to fundamentals/SFM_key_info.json\n",
      "\n",
      "Processing SHOP...\n",
      "‚úÖ Key fundamentals saved to fundamentals/SHOP_key_info.json\n",
      "\n",
      "Processing SNEX...\n",
      "‚úÖ Key fundamentals saved to fundamentals/SNEX_key_info.json\n",
      "\n",
      "Processing SNOW...\n",
      "‚úÖ Key fundamentals saved to fundamentals/SNOW_key_info.json\n",
      "\n",
      "Processing SOFI...\n",
      "‚úÖ Key fundamentals saved to fundamentals/SOFI_key_info.json\n",
      "\n",
      "Processing SYM...\n",
      "‚úÖ Key fundamentals saved to fundamentals/SYM_key_info.json\n",
      "\n",
      "Processing TBBK...\n",
      "‚úÖ Key fundamentals saved to fundamentals/TBBK_key_info.json\n",
      "\n",
      "Processing TOST...\n",
      "‚úÖ Key fundamentals saved to fundamentals/TOST_key_info.json\n",
      "\n",
      "Processing TSLA...\n",
      "‚úÖ Key fundamentals saved to fundamentals/TSLA_key_info.json\n",
      "\n",
      "Processing TSM...\n",
      "‚úÖ Key fundamentals saved to fundamentals/TSM_key_info.json\n",
      "\n",
      "Processing TSSI...\n",
      "‚úÖ Key fundamentals saved to fundamentals/TSSI_key_info.json\n",
      "\n",
      "Processing URBN...\n",
      "‚úÖ Key fundamentals saved to fundamentals/URBN_key_info.json\n",
      "\n",
      "Processing VEEV...\n",
      "‚úÖ Key fundamentals saved to fundamentals/VEEV_key_info.json\n",
      "\n",
      "Processing VRT...\n",
      "‚úÖ Key fundamentals saved to fundamentals/VRT_key_info.json\n",
      "\n",
      "Processing WMT...\n",
      "‚úÖ Key fundamentals saved to fundamentals/WMT_key_info.json\n",
      "\n",
      "Processing XOM...\n",
      "‚úÖ Key fundamentals saved to fundamentals/XOM_key_info.json\n",
      "\n",
      "Processing ZS...\n",
      "‚úÖ Key fundamentals saved to fundamentals/ZS_key_info.json\n",
      "\n",
      "Completed processing fundamentals for 63 tickers\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import json\n",
    "import os\n",
    "\n",
    "def extract_key_fundamentals(ticker):\n",
    "   \"\"\"Extract key fundamental metrics for analysis\"\"\"\n",
    "   \n",
    "   ticker_obj = yf.Ticker(ticker)\n",
    "   info = ticker_obj.info\n",
    "   \n",
    "   # Key metrics for stock analysis\n",
    "   key_metrics = {\n",
    "       'company_info': {\n",
    "           'symbol': info.get('symbol'),\n",
    "           'longName': info.get('longName'),\n",
    "           'sector': info.get('sector'),\n",
    "           'industry': info.get('industry')\n",
    "       },\n",
    "       'valuation': {\n",
    "           'marketCap': info.get('marketCap'),\n",
    "           'currentPrice': info.get('currentPrice'),\n",
    "           'trailingPE': info.get('trailingPE'),\n",
    "           'forwardPE': info.get('forwardPE'),\n",
    "           'priceToBook': info.get('priceToBook'),\n",
    "           'priceToSales': info.get('priceToSalesTrailing12Months')\n",
    "       },\n",
    "       'financial_performance': {\n",
    "           'totalRevenue': info.get('totalRevenue'),\n",
    "           'netIncomeToCommon': info.get('netIncomeToCommon'),\n",
    "           'returnOnAssets': info.get('returnOnAssets'),\n",
    "           'returnOnEquity': info.get('returnOnEquity'),\n",
    "           'profitMargins': info.get('profitMargins'),\n",
    "           'operatingMargins': info.get('operatingMargins')\n",
    "       },\n",
    "       'balance_sheet': {\n",
    "           'totalCash': info.get('totalCash'),\n",
    "           'totalDebt': info.get('totalDebt'),\n",
    "           'bookValue': info.get('bookValue'),\n",
    "           'totalCashPerShare': info.get('totalCashPerShare')\n",
    "       },\n",
    "       'growth_metrics': {\n",
    "           'earningsGrowth': info.get('earningsGrowth'),\n",
    "           'revenueGrowth': info.get('revenueGrowth'),\n",
    "           'earningsQuarterlyGrowth': info.get('earningsQuarterlyGrowth')\n",
    "       },\n",
    "       'dividend_info': {\n",
    "           'dividendRate': info.get('dividendRate'),\n",
    "           'dividendYield': info.get('dividendYield'),\n",
    "           'payoutRatio': info.get('payoutRatio')\n",
    "       }\n",
    "   }\n",
    "   \n",
    "   return key_metrics\n",
    "\n",
    "# Create fundamentals folder\n",
    "os.makedirs('fundamentals', exist_ok=True)\n",
    "\n",
    "# Extract key metrics for all tickers\n",
    "for ticker in tickers:\n",
    "   print(f\"\\nProcessing {ticker}...\")\n",
    "   try:\n",
    "       key_data = extract_key_fundamentals(ticker)\n",
    "       \n",
    "       # Save to file\n",
    "       filename = f'fundamentals/{ticker}_key_info.json'\n",
    "       with open(filename, 'w') as f:\n",
    "           json.dump(key_data, f, indent=2, default=str)\n",
    "       \n",
    "       print(f\"‚úÖ Key fundamentals saved to {filename}\")\n",
    "       \n",
    "   except Exception as e:\n",
    "       print(f\"‚ùå Error processing {ticker}: {e}\")\n",
    "\n",
    "print(f\"\\nCompleted processing fundamentals for {len(tickers)} tickers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96b18fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting 5 years of quarterly fundamentals for all tickers...\n",
      "\n",
      "Processing quarterly data for AAPL...\n",
      "‚úÖ 5 quarters of data saved to fundamentals/AAPL_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $95,359,000,000\n",
      "    Net Income: $24,780,000,000\n",
      "  2024-12-31:\n",
      "    Revenue: $124,300,000,000\n",
      "    Net Income: $36,330,000,000\n",
      "\n",
      "Processing quarterly data for ACMR...\n",
      "‚úÖ 5 quarters of data saved to fundamentals/ACMR_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $172,347,000\n",
      "    Net Income: $20,380,000\n",
      "  2024-12-31:\n",
      "    Revenue: $223,471,000\n",
      "    Net Income: $31,080,000\n",
      "\n",
      "Processing quarterly data for AFRM...\n",
      "‚úÖ 6 quarters of data saved to fundamentals/AFRM_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $783,134,000\n",
      "    Net Income: $2,804,000\n",
      "  2024-12-31:\n",
      "    Revenue: $866,381,000\n",
      "    Net Income: $80,360,000\n",
      "\n",
      "Processing quarterly data for ALAB...\n",
      "‚úÖ 5 quarters of data saved to fundamentals/ALAB_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $159,442,000\n",
      "    Net Income: $31,819,000\n",
      "  2024-12-31:\n",
      "    Revenue: $141,096,000\n",
      "    Net Income: $24,713,000\n",
      "\n",
      "Processing quarterly data for AMSC...\n",
      "‚úÖ 6 quarters of data saved to fundamentals/AMSC_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $66,655,000\n",
      "    Net Income: $1,205,000\n",
      "  2024-12-31:\n",
      "    Revenue: $61,403,000\n",
      "    Net Income: $2,465,000\n",
      "\n",
      "Processing quarterly data for AMZN...\n",
      "‚úÖ 5 quarters of data saved to fundamentals/AMZN_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $155,667,000,000\n",
      "    Net Income: $17,127,000,000\n",
      "  2024-12-31:\n",
      "    Revenue: $187,792,000,000\n",
      "    Net Income: $20,004,000,000\n",
      "\n",
      "Processing quarterly data for ANET...\n",
      "‚úÖ 6 quarters of data saved to fundamentals/ANET_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $2,004,800,000\n",
      "    Net Income: $813,800,000\n",
      "  2024-12-31:\n",
      "    Revenue: $1,930,436,000\n",
      "    Net Income: $800,996,000\n",
      "\n",
      "Processing quarterly data for APH...\n",
      "‚úÖ 5 quarters of data saved to fundamentals/APH_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $4,811,000,000\n",
      "    Net Income: $737,800,000\n",
      "  2024-12-31:\n",
      "    Revenue: $4,317,800,000\n",
      "    Net Income: $746,200,000\n",
      "\n",
      "Processing quarterly data for ATAT...\n",
      "‚úÖ 5 quarters of data saved to fundamentals/ATAT_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $1,905,814,000\n",
      "    Net Income: $242,703,000\n",
      "  2024-12-31:\n",
      "    Revenue: $2,084,010,000\n",
      "    Net Income: $330,149,000\n",
      "\n",
      "Processing quarterly data for ATI...\n",
      "‚úÖ 5 quarters of data saved to fundamentals/ATI_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $1,144,400,000\n",
      "    Net Income: $97,000,000\n",
      "  2024-12-31:\n",
      "    Revenue: $1,172,700,000\n",
      "    Net Income: $137,100,000\n",
      "\n",
      "Processing quarterly data for BK...\n",
      "‚úÖ 6 quarters of data saved to fundamentals/BK_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $4,687,000,000\n",
      "    Net Income: $1,220,000,000\n",
      "  2024-12-31:\n",
      "    Revenue: $4,760,000,000\n",
      "    Net Income: $1,155,000,000\n",
      "\n",
      "Processing quarterly data for BRK-B...\n",
      "‚úÖ 6 quarters of data saved to fundamentals/BRK-B_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $83,290,000,000\n",
      "    Net Income: $4,603,000,000\n",
      "  2024-12-31:\n",
      "    Revenue: $101,468,000,000\n",
      "    Net Income: $19,694,000,000\n",
      "\n",
      "Processing quarterly data for CCJ...\n",
      "‚úÖ 6 quarters of data saved to fundamentals/CCJ_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $789,432,000\n",
      "    Net Income: $69,764,000\n",
      "  2024-12-31:\n",
      "    Revenue: $1,183,173,000\n",
      "    Net Income: $135,473,000\n",
      "\n",
      "Processing quarterly data for CLS...\n",
      "‚úÖ 5 quarters of data saved to fundamentals/CLS_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $2,648,600,000\n",
      "    Net Income: $86,200,000\n",
      "  2024-12-31:\n",
      "    Revenue: $2,545,700,000\n",
      "    Net Income: $135,000,000\n",
      "\n",
      "Processing quarterly data for COIN...\n",
      "‚úÖ 6 quarters of data saved to fundamentals/COIN_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $2,034,295,000\n",
      "    Net Income: $65,608,000\n",
      "  2024-12-31:\n",
      "    Revenue: $2,271,637,000\n",
      "    Net Income: $1,291,176,000\n",
      "\n",
      "Processing quarterly data for CRCL...\n",
      "‚ùå Error processing CRCL: Timestamp('2024-03-31 00:00:00')\n",
      "\n",
      "Processing quarterly data for CRWD...\n",
      "‚úÖ 6 quarters of data saved to fundamentals/CRWD_quarterly_key_metrics.json\n",
      "  2025-04-30:\n",
      "    Revenue: $1,103,434,000\n",
      "    Net Income: $-110,207,000\n",
      "  2025-01-31:\n",
      "    Revenue: $1,058,538,000\n",
      "    Net Income: $-92,282,000\n",
      "\n",
      "Processing quarterly data for C...\n",
      "‚úÖ 5 quarters of data saved to fundamentals/C_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $21,601,000,000\n",
      "    Net Income: $4,064,000,000\n",
      "  2024-12-31:\n",
      "    Revenue: $19,586,000,000\n",
      "    Net Income: $2,856,000,000\n",
      "\n",
      "Processing quarterly data for DASH...\n",
      "‚úÖ 5 quarters of data saved to fundamentals/DASH_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $3,032,000,000\n",
      "    Net Income: $193,000,000\n",
      "  2024-12-31:\n",
      "    Revenue: $2,873,000,000\n",
      "    Net Income: $141,000,000\n",
      "\n",
      "Processing quarterly data for DAVE...\n",
      "‚úÖ 6 quarters of data saved to fundamentals/DAVE_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $107,979,000\n",
      "    Net Income: $28,812,000\n",
      "  2024-12-31:\n",
      "    Revenue: $100,840,000\n",
      "    Net Income: $16,806,000\n",
      "\n",
      "Processing quarterly data for DOCS...\n",
      "‚úÖ 6 quarters of data saved to fundamentals/DOCS_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $138,288,000\n",
      "    Net Income: $62,458,000\n",
      "  2024-12-31:\n",
      "    Revenue: $168,603,000\n",
      "    Net Income: $75,196,000\n",
      "\n",
      "Processing quarterly data for FIX...\n",
      "‚úÖ 5 quarters of data saved to fundamentals/FIX_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $1,831,286,000\n",
      "    Net Income: $169,289,000\n",
      "  2024-12-31:\n",
      "    Revenue: $1,867,804,000\n",
      "    Net Income: $145,870,000\n",
      "\n",
      "Processing quarterly data for FRFHF...\n",
      "‚úÖ 6 quarters of data saved to fundamentals/FRFHF_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $7,479,300,000\n",
      "    Net Income: $945,700,000\n",
      "  2024-12-31:\n",
      "    Revenue: $7,696,400,000\n",
      "    Net Income: $1,152,200,000\n",
      "\n",
      "Processing quarterly data for FUTU...\n",
      "‚úÖ 5 quarters of data saved to fundamentals/FUTU_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $4,694,637,000\n",
      "    Net Income: $2,145,323,000\n",
      "  2024-12-31:\n",
      "    Revenue: $4,432,548,000\n",
      "    Net Income: $1,871,704,000\n",
      "\n",
      "Processing quarterly data for GOOGL...\n",
      "‚úÖ 5 quarters of data saved to fundamentals/GOOGL_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $90,234,000,000\n",
      "    Net Income: $34,540,000,000\n",
      "  2024-12-31:\n",
      "    Revenue: $96,469,000,000\n",
      "    Net Income: $26,536,000,000\n",
      "\n",
      "Processing quarterly data for HEI...\n",
      "‚úÖ 5 quarters of data saved to fundamentals/HEI_quarterly_key_metrics.json\n",
      "  2025-04-30:\n",
      "    Revenue: $1,097,820,000\n",
      "    Net Income: $156,793,000\n",
      "  2025-01-31:\n",
      "    Revenue: $1,030,222,000\n",
      "    Net Income: $167,955,000\n",
      "\n",
      "Processing quarterly data for HOOD...\n",
      "‚úÖ 6 quarters of data saved to fundamentals/HOOD_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $927,000,000\n",
      "    Net Income: $336,000,000\n",
      "  2024-12-31:\n",
      "    Revenue: $1,014,000,000\n",
      "    Net Income: $916,000,000\n",
      "\n",
      "Processing quarterly data for IREN...\n",
      "‚úÖ 6 quarters of data saved to fundamentals/IREN_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $144,823,000\n",
      "    Net Income: $24,227,000\n",
      "  2024-12-31:\n",
      "    Revenue: $117,548,000\n",
      "    Net Income: $18,878,000\n",
      "\n",
      "Processing quarterly data for JBL...\n",
      "‚úÖ 6 quarters of data saved to fundamentals/JBL_quarterly_key_metrics.json\n",
      "  2025-05-31:\n",
      "    Revenue: $7,828,000,000\n",
      "    Net Income: $222,000,000\n",
      "  2025-02-28:\n",
      "    Revenue: $6,728,000,000\n",
      "    Net Income: $117,000,000\n",
      "\n",
      "Processing quarterly data for JPM...\n",
      "‚úÖ 6 quarters of data saved to fundamentals/JPM_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $45,327,000,000\n",
      "    Net Income: $14,643,000,000\n",
      "  2024-12-31:\n",
      "    Revenue: $42,791,000,000\n",
      "    Net Income: $14,005,000,000\n",
      "\n",
      "Processing quarterly data for KLAC...\n",
      "‚úÖ 6 quarters of data saved to fundamentals/KLAC_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $3,063,029,000\n",
      "    Net Income: $1,088,416,000\n",
      "  2024-12-31:\n",
      "    Revenue: $3,076,851,000\n",
      "    Net Income: $824,527,000\n",
      "\n",
      "Processing quarterly data for KNSA...\n",
      "‚úÖ 5 quarters of data saved to fundamentals/KNSA_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $137,785,000\n",
      "    Net Income: $8,539,000\n",
      "  2024-12-31:\n",
      "    Revenue: $122,536,000\n",
      "    Net Income: $-8,888,000\n",
      "\n",
      "Processing quarterly data for LIF...\n",
      "‚úÖ 6 quarters of data saved to fundamentals/LIF_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $103,624,000\n",
      "    Net Income: $4,378,000\n",
      "  2024-12-31:\n",
      "    Revenue: $115,529,000\n",
      "    Net Income: $8,498,000\n",
      "\n",
      "Processing quarterly data for META...\n",
      "‚úÖ 5 quarters of data saved to fundamentals/META_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $42,314,000,000\n",
      "    Net Income: $16,644,000,000\n",
      "  2024-12-31:\n",
      "    Revenue: $48,385,000,000\n",
      "    Net Income: $20,838,000,000\n",
      "\n",
      "Processing quarterly data for MIRM...\n",
      "‚úÖ 5 quarters of data saved to fundamentals/MIRM_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $111,585,000\n",
      "    Net Income: $-14,677,000\n",
      "  2024-12-31:\n",
      "    Revenue: $99,414,000\n",
      "    Net Income: $-23,790,000\n",
      "\n",
      "Processing quarterly data for MSFT...\n",
      "‚úÖ 5 quarters of data saved to fundamentals/MSFT_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $70,066,000,000\n",
      "    Net Income: $25,824,000,000\n",
      "  2024-12-31:\n",
      "    Revenue: $69,632,000,000\n",
      "    Net Income: $24,108,000,000\n",
      "\n",
      "Processing quarterly data for NET...\n",
      "‚úÖ 6 quarters of data saved to fundamentals/NET_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $479,087,000\n",
      "    Net Income: $-38,454,000\n",
      "  2024-12-31:\n",
      "    Revenue: $459,946,000\n",
      "    Net Income: $-12,848,000\n",
      "\n",
      "Processing quarterly data for NVDA...\n",
      "‚úÖ 7 quarters of data saved to fundamentals/NVDA_quarterly_key_metrics.json\n",
      "  2025-04-30:\n",
      "    Revenue: $44,062,000,000\n",
      "    Net Income: $18,775,000,000\n",
      "  2025-01-31:\n",
      "    Revenue: $39,331,000,000\n",
      "    Net Income: $22,091,000,000\n",
      "\n",
      "Processing quarterly data for ONC...\n",
      "‚úÖ 6 quarters of data saved to fundamentals/ONC_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $1,117,279,000\n",
      "    Net Income: $1,270,000\n",
      "  2024-12-31:\n",
      "    Revenue: $1,127,824,000\n",
      "    Net Income: $-151,881,000\n",
      "\n",
      "Processing quarterly data for OUST...\n",
      "‚úÖ 6 quarters of data saved to fundamentals/OUST_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $32,632,000\n",
      "    Net Income: $-22,017,000\n",
      "  2024-12-31:\n",
      "    Revenue: $30,092,000\n",
      "    Net Income: $-23,737,000\n",
      "\n",
      "Processing quarterly data for PLTR...\n",
      "‚úÖ 6 quarters of data saved to fundamentals/PLTR_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $883,855,000\n",
      "    Net Income: $214,031,000\n",
      "  2024-12-31:\n",
      "    Revenue: $827,519,000\n",
      "    Net Income: $79,009,000\n",
      "\n",
      "Processing quarterly data for PWR...\n",
      "‚úÖ 6 quarters of data saved to fundamentals/PWR_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $6,233,334,000\n",
      "    Net Income: $144,258,000\n",
      "  2024-12-31:\n",
      "    Revenue: $6,553,422,000\n",
      "    Net Income: $305,120,000\n",
      "\n",
      "Processing quarterly data for RBLX...\n",
      "‚úÖ 6 quarters of data saved to fundamentals/RBLX_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $1,035,207,000\n",
      "    Net Income: $-215,056,000\n",
      "  2024-12-31:\n",
      "    Revenue: $988,183,000\n",
      "    Net Income: $-219,573,000\n",
      "\n",
      "Processing quarterly data for RKLB...\n",
      "‚úÖ 6 quarters of data saved to fundamentals/RKLB_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $122,569,000\n",
      "    Net Income: $-60,616,000\n",
      "  2024-12-31:\n",
      "    Revenue: $132,388,000\n",
      "    Net Income: $-52,345,000\n",
      "\n",
      "Processing quarterly data for RMBS...\n",
      "‚úÖ 6 quarters of data saved to fundamentals/RMBS_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $166,664,000\n",
      "    Net Income: $60,303,000\n",
      "  2024-12-31:\n",
      "    Revenue: $161,102,000\n",
      "    Net Income: $62,202,000\n",
      "\n",
      "Processing quarterly data for RYTM...\n",
      "‚úÖ 5 quarters of data saved to fundamentals/RYTM_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $32,704,000\n",
      "    Net Income: $-49,498,000\n",
      "  2024-12-31:\n",
      "    Revenue: $41,830,000\n",
      "    Net Income: $-43,292,000\n",
      "\n",
      "Processing quarterly data for SFM...\n",
      "‚úÖ 5 quarters of data saved to fundamentals/SFM_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $2,236,436,000\n",
      "    Net Income: $180,026,000\n",
      "  2024-12-31:\n",
      "    Revenue: $1,996,228,000\n",
      "    Net Income: $79,602,000\n",
      "\n",
      "Processing quarterly data for SHOP...\n",
      "‚úÖ 6 quarters of data saved to fundamentals/SHOP_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $2,360,000,000\n",
      "    Net Income: $-682,000,000\n",
      "  2024-12-31:\n",
      "    Revenue: $2,812,000,000\n",
      "    Net Income: $1,293,000,000\n",
      "\n",
      "Processing quarterly data for SNEX...\n",
      "‚úÖ 5 quarters of data saved to fundamentals/SNEX_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $36,890,700,000\n",
      "    Net Income: $71,700,000\n",
      "  2024-12-31:\n",
      "    Revenue: $27,935,300,000\n",
      "    Net Income: $85,100,000\n",
      "\n",
      "Processing quarterly data for SNOW...\n",
      "‚ùå Error processing SNOW: Timestamp('2024-01-31 00:00:00')\n",
      "\n",
      "Processing quarterly data for SOFI...\n",
      "‚úÖ 6 quarters of data saved to fundamentals/SOFI_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $771,759,000\n",
      "    Net Income: $71,116,000\n",
      "  2024-12-31:\n",
      "    Revenue: $734,125,000\n",
      "    Net Income: $332,473,000\n",
      "\n",
      "Processing quarterly data for SYM...\n",
      "‚úÖ 5 quarters of data saved to fundamentals/SYM_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $549,651,000\n",
      "    Net Income: $-3,925,000\n",
      "  2024-12-31:\n",
      "    Revenue: $486,693,000\n",
      "    Net Income: $-3,476,000\n",
      "\n",
      "Processing quarterly data for TBBK...\n",
      "‚úÖ 6 quarters of data saved to fundamentals/TBBK_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $175,385,000\n",
      "    Net Income: $57,173,000\n",
      "  2024-12-31:\n",
      "    Revenue: $149,226,000\n",
      "    Net Income: $55,908,000\n",
      "\n",
      "Processing quarterly data for TOST...\n",
      "‚úÖ 6 quarters of data saved to fundamentals/TOST_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $1,337,000,000\n",
      "    Net Income: $56,000,000\n",
      "  2024-12-31:\n",
      "    Revenue: $1,338,000,000\n",
      "    Net Income: $32,000,000\n",
      "\n",
      "Processing quarterly data for TSLA...\n",
      "‚úÖ 6 quarters of data saved to fundamentals/TSLA_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $19,335,000,000\n",
      "    Net Income: $409,000,000\n",
      "  2024-12-31:\n",
      "    Revenue: $25,707,000,000\n",
      "    Net Income: $2,356,000,000\n",
      "\n",
      "Processing quarterly data for TSM...\n",
      "‚ùå Error processing TSM: Timestamp('2025-06-30 00:00:00')\n",
      "\n",
      "Processing quarterly data for TSSI...\n",
      "‚úÖ 5 quarters of data saved to fundamentals/TSSI_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $98,959,000\n",
      "    Net Income: $2,979,000\n",
      "  2024-12-31:\n",
      "    Revenue: $50,025,000\n",
      "    Net Income: $1,913,000\n",
      "\n",
      "Processing quarterly data for URBN...\n",
      "‚úÖ 6 quarters of data saved to fundamentals/URBN_quarterly_key_metrics.json\n",
      "  2025-04-30:\n",
      "    Revenue: $1,329,501,000\n",
      "    Net Income: $108,347,000\n",
      "  2025-01-31:\n",
      "    Revenue: $1,636,120,000\n",
      "    Net Income: $120,301,000\n",
      "\n",
      "Processing quarterly data for VEEV...\n",
      "‚ùå Error processing VEEV: Timestamp('2023-10-31 00:00:00')\n",
      "\n",
      "Processing quarterly data for VRT...\n",
      "‚úÖ 6 quarters of data saved to fundamentals/VRT_quarterly_key_metrics.json\n",
      "  2025-03-31:\n",
      "    Revenue: $2,036,000,000\n",
      "    Net Income: $164,500,000\n",
      "  2024-12-31:\n",
      "    Revenue: $2,346,400,000\n",
      "    Net Income: $147,000,000\n",
      "\n",
      "Processing quarterly data for WMT...\n",
      "‚úÖ 6 quarters of data saved to fundamentals/WMT_quarterly_key_metrics.json\n",
      "  2025-04-30:\n",
      "    Revenue: $165,609,000,000\n",
      "    Net Income: $4,487,000,000\n",
      "  2025-01-31:\n",
      "    Revenue: $180,554,000,000\n",
      "    Net Income: $5,254,000,000\n",
      "\n",
      "Processing quarterly data for XOM...\n",
      "‚ùå Error processing XOM: Timestamp('2023-12-31 00:00:00')\n",
      "\n",
      "Processing quarterly data for ZS...\n",
      "‚ùå Error processing ZS: Timestamp('2024-01-31 00:00:00')\n",
      "\n",
      "üéâ Completed processing quarterly fundamentals for 63 tickers\n",
      "Now we have ~20 quarters (5 years) of data instead of just 4!\n",
      "This will significantly improve our regression model reliability.\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Get tickers from data folder\n",
    "data_files = [f for f in os.listdir('data') if f.endswith('_stock_data.csv')]\n",
    "tickers = [f.replace('_stock_data.csv', '') for f in data_files]\n",
    "\n",
    "def extract_quarterly_key_fundamentals(ticker):\n",
    "    \"\"\"Extract key quarterly fundamental metrics\"\"\"\n",
    "    \n",
    "    ticker_obj = yf.Ticker(ticker)\n",
    "    \n",
    "    # Get quarterly data\n",
    "    quarterly_financials = ticker_obj.quarterly_financials\n",
    "    quarterly_balance_sheet = ticker_obj.quarterly_balance_sheet\n",
    "    quarterly_cashflow = ticker_obj.quarterly_cashflow\n",
    "    \n",
    "    # Extract key metrics for last 20 quarters - 5 years\n",
    "    quarterly_data = {}\n",
    "    \n",
    "    if not quarterly_financials.empty:\n",
    "        for date in quarterly_financials.columns[:20]:  # Last 20 quarters\n",
    "            quarter_str = date.strftime('%Y-%m-%d') if hasattr(date, 'strftime') else str(date)\n",
    "            \n",
    "            quarterly_data[quarter_str] = {\n",
    "                'income_statement': {\n",
    "                    'total_revenue': quarterly_financials.loc['Total Revenue', date] if 'Total Revenue' in quarterly_financials.index else None,\n",
    "                    'net_interest_income': quarterly_financials.loc['Net Interest Income', date] if 'Net Interest Income' in quarterly_financials.index else None,\n",
    "                    'net_income': quarterly_financials.loc['Net Income', date] if 'Net Income' in quarterly_financials.index else None,\n",
    "                    'diluted_eps': quarterly_financials.loc['Diluted EPS', date] if 'Diluted EPS' in quarterly_financials.index else None\n",
    "                },\n",
    "                'balance_sheet': {\n",
    "                    'total_assets': quarterly_balance_sheet.loc['Total Assets', date] if 'Total Assets' in quarterly_balance_sheet.index else None,\n",
    "                    'total_debt': quarterly_balance_sheet.loc['Total Debt', date] if 'Total Debt' in quarterly_balance_sheet.index else None,\n",
    "                    'stockholders_equity': quarterly_balance_sheet.loc['Stockholders Equity', date] if 'Stockholders Equity' in quarterly_balance_sheet.index else None,\n",
    "                    'book_value': quarterly_balance_sheet.loc['Tangible Book Value', date] if 'Tangible Book Value' in quarterly_balance_sheet.index else None\n",
    "                },\n",
    "                'cash_flow': {\n",
    "                    'operating_cash_flow': quarterly_cashflow.loc['Operating Cash Flow', date] if 'Operating Cash Flow' in quarterly_cashflow.index else None,\n",
    "                    'free_cash_flow': quarterly_cashflow.loc['Free Cash Flow', date] if 'Free Cash Flow' in quarterly_cashflow.index else None,\n",
    "                    'capital_expenditure': quarterly_cashflow.loc['Capital Expenditure', date] if 'Capital Expenditure' in quarterly_cashflow.index else None\n",
    "                }\n",
    "            }\n",
    "    \n",
    "    return quarterly_data\n",
    "\n",
    "# Extract quarterly data for all tickers\n",
    "print(\"Extracting 5 years of quarterly fundamentals for all tickers...\")\n",
    "for ticker in tickers:\n",
    "    print(f\"\\nProcessing quarterly data for {ticker}...\")\n",
    "    try:\n",
    "        quarterly_data = extract_quarterly_key_fundamentals(ticker)\n",
    "        \n",
    "        # Save to file (this will overwrite the old 4-quarter files)\n",
    "        filename = f'fundamentals/{ticker}_quarterly_key_metrics.json'\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(quarterly_data, f, indent=2, default=str)\n",
    "        \n",
    "        print(f\"‚úÖ {len(quarterly_data)} quarters of data saved to {filename}\")\n",
    "        \n",
    "        # Show summary for first few quarters\n",
    "        count = 0\n",
    "        for quarter, data in quarterly_data.items():\n",
    "            if count < 2:  # Show only first 2 quarters to avoid clutter\n",
    "                print(f\"  {quarter}:\")\n",
    "                if data['income_statement']['total_revenue']:\n",
    "                    print(f\"    Revenue: ${data['income_statement']['total_revenue']:,.0f}\")\n",
    "                if data['income_statement']['net_income']:\n",
    "                    print(f\"    Net Income: ${data['income_statement']['net_income']:,.0f}\")\n",
    "            count += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing {ticker}: {e}\")\n",
    "\n",
    "print(f\"\\nüéâ Completed processing quarterly fundamentals for {len(tickers)} tickers\")\n",
    "print(\"Now we have ~20 quarters (5 years) of data instead of just 4!\")\n",
    "print(\"This will significantly improve our regression model reliability.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06dfb45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from matplotlib) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\prao5\\documents\\github\\ucb\\ucb_capstone\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36f84674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "JPM - Latest Available Quarters:\n",
      "  2025-03-31\n",
      "  2024-12-31\n",
      "  2024-09-30\n",
      "  2024-06-30\n",
      "\n",
      "BAC - Latest Available Quarters:\n",
      "  2025-03-31\n",
      "  2024-12-31\n",
      "  2024-09-30\n",
      "  2024-06-30\n",
      "\n",
      "WFC - Latest Available Quarters:\n",
      "  2025-03-31\n",
      "  2024-12-31\n",
      "  2024-09-30\n",
      "  2024-06-30\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "\n",
    "def get_latest_quarterly_data(ticker):\n",
    "    \"\"\"Try to get the most recent quarterly data from yfinance\"\"\"\n",
    "    \n",
    "    ticker_obj = yf.Ticker(ticker)\n",
    "    \n",
    "    # Get quarterly financials\n",
    "    quarterly_financials = ticker_obj.quarterly_financials\n",
    "    quarterly_balance_sheet = ticker_obj.quarterly_balance_sheet\n",
    "    \n",
    "    print(f\"\\n{ticker} - Latest Available Quarters:\")\n",
    "    if not quarterly_financials.empty:\n",
    "        latest_quarters = quarterly_financials.columns[:4]  # Show last 4 quarters\n",
    "        for date in latest_quarters:\n",
    "            print(f\"  {date.strftime('%Y-%m-%d')}\")\n",
    "    \n",
    "    return quarterly_financials, quarterly_balance_sheet\n",
    "\n",
    "# Test with a few tickers\n",
    "test_tickers = ['JPM', 'BAC', 'WFC']  # Major banks report quickly\n",
    "\n",
    "for ticker in test_tickers:\n",
    "    financials, balance_sheet = get_latest_quarterly_data(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "431349a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ COMPLETE STOCK PREDICTION SYSTEM\n",
      "==================================================\n",
      "\n",
      "üìä EXAMPLE 1: Single Ticker Analysis\n",
      "----------------------------------------\n",
      "\n",
      "üìä EXAMPLE 2: Multiple Ticker Analysis\n",
      "----------------------------------------\n",
      "\n",
      "üí° USAGE INSTRUCTIONS:\n",
      "------------------------------\n",
      "1. For single ticker: analyze_single_ticker('TICKER')\n",
      "2. For multiple tickers: analyze_multiple_tickers(['TICKER1', 'TICKER2', ...])\n",
      "3. Results are automatically saved to 'results/' folder\n",
      "4. Requires internet connection for yfinance data download\n",
      "5. Optional: Install scikit-learn and xgboost for ML methods\n",
      "\n",
      "üìÅ FOLDER STRUCTURE:\n",
      "‚îú‚îÄ‚îÄ data/              # Stock price data (CSV)\n",
      "‚îú‚îÄ‚îÄ fundamentals/      # Quarterly fundamental data (JSON)\n",
      "‚îî‚îÄ‚îÄ results/           # Prediction results and summaries\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Try to import ML libraries (optional)\n",
    "try:\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.metrics import r2_score, mean_absolute_error\n",
    "    import xgboost as xgb\n",
    "    ML_AVAILABLE = True\n",
    "except ImportError:\n",
    "    ML_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è ML libraries not available. Using fundamental methods only.\")\n",
    "\n",
    "class CompletePredictionSystem:\n",
    "    \"\"\"Complete stock prediction system integrating all our developed methods\"\"\"\n",
    "    \n",
    "    def __init__(self, ticker):\n",
    "        self.ticker = ticker.upper()\n",
    "        self.data_folder = 'data'\n",
    "        self.fundamentals_folder = 'fundamentals'\n",
    "        self.results_folder = 'results'\n",
    "        \n",
    "        # Create folders if they don't exist\n",
    "        for folder in [self.data_folder, self.fundamentals_folder, self.results_folder]:\n",
    "            os.makedirs(folder, exist_ok=True)\n",
    "        \n",
    "        # Initialize data containers\n",
    "        self.stock_data = None\n",
    "        self.quarterly_fundamentals = None\n",
    "        self.key_info = None\n",
    "        self.correlation_data = None\n",
    "        \n",
    "        print(f\"üéØ Initializing Complete Prediction System for {self.ticker}\")\n",
    "    \n",
    "    def download_stock_data(self, period=\"2y\"):\n",
    "        \"\"\"Download stock price data\"\"\"\n",
    "        try:\n",
    "            print(f\"üìä Downloading stock data for {self.ticker}...\")\n",
    "            ticker_obj = yf.Ticker(self.ticker)\n",
    "            self.stock_data = ticker_obj.history(period=period)\n",
    "            \n",
    "            if self.stock_data.empty:\n",
    "                raise ValueError(f\"No stock data found for {self.ticker}\")\n",
    "            \n",
    "            # Save to CSV\n",
    "            filepath = f\"{self.data_folder}/{self.ticker}_stock_data.csv\"\n",
    "            self.stock_data.to_csv(filepath)\n",
    "            print(f\"‚úÖ Stock data saved to {filepath}\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error downloading stock data: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def download_fundamentals(self):\n",
    "        \"\"\"Download quarterly fundamentals and key info\"\"\"\n",
    "        try:\n",
    "            print(f\"üìà Downloading fundamentals for {self.ticker}...\")\n",
    "            ticker_obj = yf.Ticker(self.ticker)\n",
    "            \n",
    "            # Get quarterly data\n",
    "            quarterly_financials = ticker_obj.quarterly_financials\n",
    "            quarterly_balance_sheet = ticker_obj.quarterly_balance_sheet\n",
    "            quarterly_cashflow = ticker_obj.quarterly_cashflow\n",
    "            \n",
    "            # Extract quarterly fundamentals\n",
    "            quarterly_data = {}\n",
    "            \n",
    "            if not quarterly_financials.empty:\n",
    "                for date in quarterly_financials.columns[:8]:  # Last 8 quarters\n",
    "                    quarter_str = date.strftime('%Y-%m-%d') if hasattr(date, 'strftime') else str(date)\n",
    "                    \n",
    "                    quarterly_data[quarter_str] = {\n",
    "                        'income_statement': {\n",
    "                            'total_revenue': self._safe_extract(quarterly_financials, 'Total Revenue', date),\n",
    "                            'net_interest_income': self._safe_extract(quarterly_financials, 'Net Interest Income', date),\n",
    "                            'net_income': self._safe_extract(quarterly_financials, 'Net Income', date),\n",
    "                            'diluted_eps': self._safe_extract(quarterly_financials, 'Diluted EPS', date)\n",
    "                        },\n",
    "                        'balance_sheet': {\n",
    "                            'total_assets': self._safe_extract(quarterly_balance_sheet, 'Total Assets', date),\n",
    "                            'total_debt': self._safe_extract(quarterly_balance_sheet, 'Total Debt', date),\n",
    "                            'stockholders_equity': self._safe_extract(quarterly_balance_sheet, 'Stockholders Equity', date),\n",
    "                            'book_value': self._safe_extract(quarterly_balance_sheet, 'Tangible Book Value', date)\n",
    "                        },\n",
    "                        'cash_flow': {\n",
    "                            'operating_cash_flow': self._safe_extract(quarterly_cashflow, 'Operating Cash Flow', date),\n",
    "                            'free_cash_flow': self._safe_extract(quarterly_cashflow, 'Free Cash Flow', date),\n",
    "                            'capital_expenditure': self._safe_extract(quarterly_cashflow, 'Capital Expenditure', date)\n",
    "                        }\n",
    "                    }\n",
    "            \n",
    "            # Save quarterly fundamentals\n",
    "            quarterly_file = f\"{self.fundamentals_folder}/{self.ticker}_quarterly_key_metrics.json\"\n",
    "            with open(quarterly_file, 'w') as f:\n",
    "                json.dump(quarterly_data, f, indent=2, default=str)\n",
    "            \n",
    "            # Get key info\n",
    "            info = ticker_obj.info\n",
    "            key_info = {\n",
    "                'valuation': {\n",
    "                    'marketCap': info.get('marketCap'),\n",
    "                    'currentPrice': info.get('currentPrice'),\n",
    "                    'beta': info.get('beta')\n",
    "                },\n",
    "                'dividend_info': {\n",
    "                    'dividendRate': info.get('dividendRate'),\n",
    "                    'dividendYield': info.get('dividendYield'),\n",
    "                    'payoutRatio': info.get('payoutRatio')\n",
    "                },\n",
    "                'basic_info': {\n",
    "                    'sector': info.get('sector'),\n",
    "                    'industry': info.get('industry'),\n",
    "                    'longName': info.get('longName')\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Save key info\n",
    "            info_file = f\"{self.fundamentals_folder}/{self.ticker}_key_info.json\"\n",
    "            with open(info_file, 'w') as f:\n",
    "                json.dump(key_info, f, indent=2, default=str)\n",
    "            \n",
    "            self.quarterly_fundamentals = quarterly_data\n",
    "            self.key_info = key_info\n",
    "            \n",
    "            print(f\"‚úÖ Fundamentals saved: {len(quarterly_data)} quarters available\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error downloading fundamentals: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def _safe_extract(self, df, key, date):\n",
    "        \"\"\"Safely extract value from DataFrame\"\"\"\n",
    "        try:\n",
    "            if key in df.index:\n",
    "                value = df.loc[key, date]\n",
    "                return float(value) if pd.notna(value) else None\n",
    "            return None\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "# Quick fix - replace the create_correlation_dataset method in your script\n",
    "def create_correlation_dataset(self):\n",
    "    \"\"\"Create aligned dataset for correlation analysis - FIXED VERSION\"\"\"\n",
    "    try:\n",
    "        print(f\"üîó Creating correlation dataset...\")\n",
    "        \n",
    "        if self.stock_data is None or self.quarterly_fundamentals is None:\n",
    "            raise ValueError(\"Stock data and fundamentals must be downloaded first\")\n",
    "        \n",
    "        # Get shares outstanding\n",
    "        market_cap = self.key_info.get('valuation', {}).get('marketCap')\n",
    "        current_price = self.key_info.get('valuation', {}).get('currentPrice')\n",
    "        \n",
    "        if market_cap and current_price:\n",
    "            shares_outstanding = float(market_cap) / float(current_price)\n",
    "        else:\n",
    "            # Alternative calculation using recent price and market cap\n",
    "            shares_outstanding = 1e9  # Default fallback for large companies like GOOGL\n",
    "            print(\"‚ö†Ô∏è Using estimated shares outstanding\")\n",
    "        \n",
    "        correlation_data = []\n",
    "        \n",
    "        for quarter, data in self.quarterly_fundamentals.items():\n",
    "            try:\n",
    "                quarter_date = pd.to_datetime(quarter)\n",
    "                quarter_start = quarter_date - pd.DateOffset(months=3)\n",
    "                \n",
    "                # Handle timezone issues\n",
    "                stock_data_to_use = self.stock_data.copy()\n",
    "                \n",
    "                # Make all dates timezone-naive for comparison\n",
    "                if hasattr(stock_data_to_use.index, 'tz') and stock_data_to_use.index.tz is not None:\n",
    "                    stock_data_to_use.index = stock_data_to_use.index.tz_convert(None)\n",
    "                \n",
    "                if hasattr(quarter_date, 'tz') and quarter_date.tz is not None:\n",
    "                    quarter_date = quarter_date.tz_localize(None)\n",
    "                    quarter_start = quarter_start.tz_localize(None)\n",
    "                \n",
    "                # Get average stock price for quarter\n",
    "                mask = (stock_data_to_use.index >= quarter_start) & (stock_data_to_use.index <= quarter_date)\n",
    "                quarter_prices = stock_data_to_use.loc[mask, 'Close']\n",
    "                \n",
    "                avg_stock_price = quarter_prices.mean() if len(quarter_prices) > 0 else None\n",
    "                \n",
    "                if avg_stock_price and pd.notna(avg_stock_price):\n",
    "                    # Calculate per share metrics\n",
    "                    total_debt = data['balance_sheet']['total_debt']\n",
    "                    debt_per_share = (total_debt / shares_outstanding) if total_debt else None\n",
    "                    \n",
    "                    total_book_value = data['balance_sheet']['book_value']\n",
    "                    book_value_per_share = (total_book_value / shares_outstanding) if total_book_value else None\n",
    "                    \n",
    "                    diluted_eps = data['income_statement']['diluted_eps']\n",
    "                    \n",
    "                    # Calculate ratios with safety checks\n",
    "                    roe = None\n",
    "                    if diluted_eps and total_book_value and shares_outstanding:\n",
    "                        try:\n",
    "                            roe = (diluted_eps * shares_outstanding) / total_book_value\n",
    "                        except:\n",
    "                            pass\n",
    "                    \n",
    "                    pb_ratio = None\n",
    "                    if book_value_per_share and book_value_per_share > 0:\n",
    "                        pb_ratio = avg_stock_price / book_value_per_share\n",
    "                    \n",
    "                    pe_ratio = None\n",
    "                    if diluted_eps and diluted_eps > 0:\n",
    "                        pe_ratio = avg_stock_price / diluted_eps\n",
    "                    \n",
    "                    row = {\n",
    "                        'quarter': quarter,\n",
    "                        'Avg Price': float(avg_stock_price),\n",
    "                        'Earnings': float(diluted_eps) if diluted_eps else None,\n",
    "                        'Debt': float(debt_per_share) if debt_per_share else None,\n",
    "                        'Book Value': float(book_value_per_share) if book_value_per_share else None,\n",
    "                        'ROE': float(roe) if roe else None,\n",
    "                        'P/B Ratio': float(pb_ratio) if pb_ratio else None,\n",
    "                        'P/E Ratio': float(pe_ratio) if pe_ratio else None\n",
    "                    }\n",
    "                    correlation_data.append(row)\n",
    "                    \n",
    "            except Exception as quarter_error:\n",
    "                print(f\"‚ö†Ô∏è Skipping quarter {quarter}: {quarter_error}\")\n",
    "                continue\n",
    "        \n",
    "        self.correlation_data = pd.DataFrame(correlation_data) if correlation_data else None\n",
    "        \n",
    "        if self.correlation_data is not None and len(self.correlation_data) > 0:\n",
    "            print(f\"‚úÖ Correlation dataset created: {len(self.correlation_data)} quarters\")\n",
    "            print(f\"   Available data: {list(self.correlation_data.columns)}\")\n",
    "        else:\n",
    "            print(\"‚ùå Failed to create correlation dataset\")\n",
    "        \n",
    "        return self.correlation_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error creating correlation dataset: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "    \n",
    "        \n",
    "    def simple_price_prediction(self):\n",
    "        \"\"\"Method 1: Simple correlation-based prediction\"\"\"\n",
    "        try:\n",
    "            print(f\"üéØ Running simple correlation prediction...\")\n",
    "            \n",
    "            if self.correlation_data is None:\n",
    "                raise ValueError(\"Correlation dataset not available\")\n",
    "            \n",
    "            df = self.correlation_data.dropna()\n",
    "            \n",
    "            if len(df) < 3:\n",
    "                return None, \"Insufficient data for simple prediction\"\n",
    "            \n",
    "            # Determine stock type based on correlations\n",
    "            corr_matrix = df[['Avg Price', 'Book Value', 'P/B Ratio']].corr()\n",
    "            book_value_corr = abs(corr_matrix.loc['Avg Price', 'Book Value'])\n",
    "            pb_ratio_corr = abs(corr_matrix.loc['Avg Price', 'P/B Ratio'])\n",
    "            \n",
    "            stock_type = \"Value\" if book_value_corr > pb_ratio_corr else \"Growth\"\n",
    "            \n",
    "            current_price = df['Avg Price'].iloc[0]\n",
    "            current_book_value = df['Book Value'].iloc[0]\n",
    "            \n",
    "            if stock_type == \"Value\":\n",
    "                # Value stock prediction\n",
    "                df['Historical_PB'] = df['Avg Price'] / df['Book Value']\n",
    "                avg_pb_ratio = df['Historical_PB'].mean()\n",
    "                avg_roe = df['ROE'].mean() if 'ROE' in df.columns else 0.02\n",
    "                \n",
    "                next_quarter_book_value = current_book_value * (1 + avg_roe/4)\n",
    "                predicted_price = next_quarter_book_value * avg_pb_ratio\n",
    "                \n",
    "                method = f\"Book Value Growth (ROE: {avg_roe:.2%}, Avg P/B: {avg_pb_ratio:.2f})\"\n",
    "            else:\n",
    "                # Growth stock prediction\n",
    "                current_pb = df['P/B Ratio'].iloc[0]\n",
    "                pb_trend = np.polyfit(range(len(df)), df['P/B Ratio'], 1)[0]\n",
    "                \n",
    "                next_quarter_pb = current_pb + pb_trend\n",
    "                predicted_price = current_book_value * next_quarter_pb\n",
    "                \n",
    "                method = f\"P/B Trend (Current: {current_pb:.2f}, Trend: {pb_trend:+.3f})\"\n",
    "            \n",
    "            price_change = (predicted_price - current_price) / current_price * 100\n",
    "            \n",
    "            result = {\n",
    "                'method': 'Simple Correlation',\n",
    "                'stock_type': stock_type,\n",
    "                'current_price': current_price,\n",
    "                'predicted_price': predicted_price,\n",
    "                'price_change_pct': price_change,\n",
    "                'prediction_method': method,\n",
    "                'correlation_strength': max(book_value_corr, pb_ratio_corr),\n",
    "                'confidence': 'High' if max(book_value_corr, pb_ratio_corr) > 0.7 else 'Medium'\n",
    "            }\n",
    "            \n",
    "            return result, None\n",
    "            \n",
    "        except Exception as e:\n",
    "            return None, f\"Simple prediction error: {str(e)}\"\n",
    "    \n",
    "    def ml_ensemble_prediction(self):\n",
    "        \"\"\"Method 3: ML Ensemble prediction (if libraries available)\"\"\"\n",
    "        if not ML_AVAILABLE:\n",
    "            return None, \"ML libraries not available\"\n",
    "        \n",
    "        try:\n",
    "            print(f\"ü§ñ Running ML ensemble prediction...\")\n",
    "            \n",
    "            if self.correlation_data is None:\n",
    "                return None, \"Correlation dataset not available\"\n",
    "            \n",
    "            df = self.correlation_data.dropna()\n",
    "            \n",
    "            if len(df) < 4:\n",
    "                return None, \"Insufficient data for ML prediction\"\n",
    "            \n",
    "            # Prepare features\n",
    "            feature_cols = ['Book Value', 'Earnings', 'ROE', 'Debt', 'P/B Ratio']\n",
    "            available_features = [col for col in feature_cols if col in df.columns]\n",
    "            \n",
    "            X = df[available_features].fillna(0)\n",
    "            y = df['Avg Price']\n",
    "            \n",
    "            if len(X) < 3:\n",
    "                return None, \"Insufficient feature data\"\n",
    "            \n",
    "            # Split data\n",
    "            X_train = X.iloc[:-1]\n",
    "            y_train = y.iloc[:-1]\n",
    "            X_current = X.iloc[-1:].copy()\n",
    "            current_price = y.iloc[-1]\n",
    "            \n",
    "            # Scale features\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_current_scaled = scaler.transform(X_current)\n",
    "            \n",
    "            # Train models\n",
    "            models = {}\n",
    "            predictions = {}\n",
    "            \n",
    "            # Random Forest\n",
    "            try:\n",
    "                rf = RandomForestRegressor(n_estimators=50, max_depth=5, random_state=42)\n",
    "                rf.fit(X_train, y_train)\n",
    "                predictions['RandomForest'] = rf.predict(X_current)[0]\n",
    "                models['RandomForest'] = rf\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # XGBoost\n",
    "            try:\n",
    "                xgb_model = xgb.XGBRegressor(n_estimators=50, max_depth=4, random_state=42, verbosity=0)\n",
    "                xgb_model.fit(X_train, y_train)\n",
    "                predictions['XGBoost'] = xgb_model.predict(X_current)[0]\n",
    "                models['XGBoost'] = xgb_model\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            if not predictions:\n",
    "                return None, \"No ML models succeeded\"\n",
    "            \n",
    "            # Ensemble prediction\n",
    "            ensemble_prediction = np.mean(list(predictions.values()))\n",
    "            price_change = (ensemble_prediction - current_price) / current_price * 100\n",
    "            \n",
    "            # Calculate confidence\n",
    "            pred_std = np.std(list(predictions.values()))\n",
    "            confidence = \"High\" if pred_std < current_price * 0.05 else \"Medium\" if pred_std < current_price * 0.10 else \"Low\"\n",
    "            \n",
    "            result = {\n",
    "                'method': 'ML Ensemble',\n",
    "                'current_price': current_price,\n",
    "                'predicted_price': ensemble_prediction,\n",
    "                'price_change_pct': price_change,\n",
    "                'individual_predictions': predictions,\n",
    "                'confidence': confidence,\n",
    "                'feature_count': len(available_features),\n",
    "                'data_points': len(df)\n",
    "            }\n",
    "            \n",
    "            return result, None\n",
    "            \n",
    "        except Exception as e:\n",
    "            return None, f\"ML ensemble error: {str(e)}\"\n",
    "    \n",
    "    def dcf_fundamental_prediction(self):\n",
    "        \"\"\"Method 5: DCF fundamental prediction\"\"\"\n",
    "        try:\n",
    "            print(f\"üí∞ Running DCF fundamental prediction...\")\n",
    "            \n",
    "            if self.correlation_data is None or self.key_info is None:\n",
    "                return None, \"Required data not available\"\n",
    "            \n",
    "            df = self.correlation_data.dropna()\n",
    "            \n",
    "            if len(df) < 3:\n",
    "                return None, \"Insufficient data for DCF\"\n",
    "            \n",
    "            current_price = df['Avg Price'].iloc[0]\n",
    "            current_book_value = df['Book Value'].iloc[0]\n",
    "            current_earnings = df['Earnings'].iloc[0]\n",
    "            current_roe = df['ROE'].iloc[0] if pd.notna(df['ROE'].iloc[0]) else 0.1\n",
    "            \n",
    "            # Extract dividend information\n",
    "            dividend_rate = float(self.key_info.get('dividend_info', {}).get('dividendRate', 0) or 0)\n",
    "            dividend_yield = float(self.key_info.get('dividend_info', {}).get('dividendYield', 0) or 0)\n",
    "            payout_ratio = float(self.key_info.get('dividend_info', {}).get('payoutRatio', 0) or 0)\n",
    "            \n",
    "            # Calculate historical growth rates\n",
    "            if len(df) >= 4:\n",
    "                book_value_growth = df['Book Value'].pct_change().mean() * 4\n",
    "                earnings_growth = df['Earnings'].pct_change().mean() * 4\n",
    "            else:\n",
    "                book_value_growth = current_roe * 0.6\n",
    "                earnings_growth = current_roe * 0.8\n",
    "            \n",
    "            # Clean up extreme values\n",
    "            book_value_growth = np.clip(book_value_growth, -0.5, 0.5)\n",
    "            earnings_growth = np.clip(earnings_growth, -0.5, 0.5)\n",
    "            \n",
    "            # Model parameters\n",
    "            risk_free_rate = 0.04\n",
    "            equity_risk_premium = 0.06\n",
    "            beta = float(self.key_info.get('valuation', {}).get('beta', 1.2) or 1.2)\n",
    "            required_return = np.clip(risk_free_rate + beta * equity_risk_premium, 0.08, 0.20)\n",
    "            \n",
    "            # DCF Models\n",
    "            models = {}\n",
    "            \n",
    "            # Residual Income Model\n",
    "            future_roe = np.clip(current_roe, 0.05, 0.30)\n",
    "            retention_ratio = np.clip(1 - (payout_ratio if payout_ratio > 0 else 0.4), 0.3, 0.9)\n",
    "            future_book_value = current_book_value * (1 + future_roe * retention_ratio)\n",
    "            \n",
    "            if future_roe > required_return:\n",
    "                residual_income = (future_roe - required_return) * future_book_value\n",
    "                pv_residual_income = sum([residual_income * (0.8 ** i) / ((1 + required_return) ** i) \n",
    "                                        for i in range(1, 6)])\n",
    "                models['RIM'] = future_book_value + pv_residual_income\n",
    "            else:\n",
    "                models['RIM'] = future_book_value\n",
    "            \n",
    "            # Earnings Power Value\n",
    "            if current_earnings > 0:\n",
    "                normalized_earnings = current_earnings * (1 + earnings_growth * 0.5)\n",
    "                models['EPV'] = max(normalized_earnings / required_return, current_book_value * 0.8)\n",
    "            else:\n",
    "                models['EPV'] = current_book_value\n",
    "            \n",
    "            # Dividend Discount Model (if applicable)\n",
    "            if dividend_rate > 0 and payout_ratio > 0:\n",
    "                if payout_ratio < 0.8:\n",
    "                    dividend_growth = earnings_growth * (1 - payout_ratio)\n",
    "                else:\n",
    "                    dividend_growth = 0.02\n",
    "                \n",
    "                dividend_growth = np.clip(dividend_growth, 0, 0.15)\n",
    "                \n",
    "                if required_return > dividend_growth:\n",
    "                    next_year_dividend = dividend_rate * (1 + dividend_growth)\n",
    "                    models['DDM'] = next_year_dividend / (required_return - dividend_growth)\n",
    "            \n",
    "            # Weighted ensemble\n",
    "            if len(models) > 1:\n",
    "                weights = {'RIM': 0.5, 'EPV': 0.3, 'DDM': 0.2}\n",
    "            else:\n",
    "                weights = {list(models.keys())[0]: 1.0}\n",
    "            \n",
    "            # Normalize weights to available models\n",
    "            available_models = list(models.keys())\n",
    "            total_weight = sum(weights.get(model, 0) for model in available_models)\n",
    "            normalized_weights = {model: weights.get(model, 0) / total_weight for model in available_models}\n",
    "            \n",
    "            # Calculate weighted average\n",
    "            dcf_intrinsic_value = sum(models[model] * normalized_weights[model] for model in available_models)\n",
    "            \n",
    "            # Sanity checks\n",
    "            dcf_intrinsic_value = np.clip(dcf_intrinsic_value, \n",
    "                                        current_book_value * 0.3, \n",
    "                                        current_book_value * 5.0)\n",
    "            \n",
    "            price_change_pct = (dcf_intrinsic_value - current_price) / current_price * 100\n",
    "            \n",
    "            # Calculate confidence\n",
    "            model_values = list(models.values())\n",
    "            model_std = np.std(model_values) / np.mean(model_values) if len(model_values) > 1 else 0\n",
    "            \n",
    "            if model_std < 0.15 and len(df) >= 4:\n",
    "                confidence = \"High\"\n",
    "            elif model_std < 0.30 and len(df) >= 3:\n",
    "                confidence = \"Medium\"\n",
    "            else:\n",
    "                confidence = \"Low\"\n",
    "            \n",
    "            result = {\n",
    "                'method': 'DCF Fundamental',\n",
    "                'current_price': current_price,\n",
    "                'predicted_price': dcf_intrinsic_value,\n",
    "                'price_change_pct': price_change_pct,\n",
    "                'individual_models': models,\n",
    "                'model_weights': normalized_weights,\n",
    "                'confidence': confidence,\n",
    "                'fundamental_inputs': {\n",
    "                    'current_roe': current_roe,\n",
    "                    'book_value_growth': book_value_growth,\n",
    "                    'earnings_growth': earnings_growth,\n",
    "                    'required_return': required_return\n",
    "                },\n",
    "                'data_points': len(df)\n",
    "            }\n",
    "            \n",
    "            return result, None\n",
    "            \n",
    "        except Exception as e:\n",
    "            return None, f\"DCF prediction error: {str(e)}\"\n",
    "    \n",
    "    def analyze_support_consensus(self, simple_result, ml_result, dcf_result):\n",
    "        \"\"\"Analyze support/consensus across methods\"\"\"\n",
    "        try:\n",
    "            if not simple_result:\n",
    "                return None, \"No base prediction available\"\n",
    "            \n",
    "            current_price = simple_result['current_price']\n",
    "            simple_pred = simple_result['predicted_price']\n",
    "            \n",
    "            # Determine direction\n",
    "            if simple_pred > current_price * 1.02:\n",
    "                direction = 'UP'\n",
    "            elif simple_pred < current_price * 0.98:\n",
    "                direction = 'DOWN'\n",
    "            else:\n",
    "                direction = 'FLAT'\n",
    "            \n",
    "            # Check support from other methods\n",
    "            supporting_methods = []\n",
    "            \n",
    "            # Check ML support\n",
    "            if ml_result:\n",
    "                ml_pred = ml_result['predicted_price']\n",
    "                if direction == 'UP' and ml_pred > current_price * 1.02:\n",
    "                    supporting_methods.append('ML')\n",
    "                elif direction == 'DOWN' and ml_pred < current_price * 0.98:\n",
    "                    supporting_methods.append('ML')\n",
    "                elif direction == 'FLAT' and current_price * 0.98 <= ml_pred <= current_price * 1.02:\n",
    "                    supporting_methods.append('ML')\n",
    "            \n",
    "            # Check DCF support\n",
    "            if dcf_result:\n",
    "                dcf_pred = dcf_result['predicted_price']\n",
    "                if direction == 'UP' and dcf_pred > current_price * 1.02:\n",
    "                    supporting_methods.append('DCF')\n",
    "                elif direction == 'DOWN' and dcf_pred < current_price * 0.98:\n",
    "                    supporting_methods.append('DCF')\n",
    "                elif direction == 'FLAT' and current_price * 0.98 <= dcf_pred <= current_price * 1.02:\n",
    "                    supporting_methods.append('DCF')\n",
    "            \n",
    "            # Create consensus prediction\n",
    "            support_count = len(supporting_methods)\n",
    "            if support_count == 0:\n",
    "                consensus_prediction = direction\n",
    "            elif support_count == 1:\n",
    "                consensus_prediction = f\"{direction}+\"\n",
    "            else:\n",
    "                consensus_prediction = f\"{direction}++\"\n",
    "            \n",
    "            return {\n",
    "                'direction': direction,\n",
    "                'consensus_prediction': consensus_prediction,\n",
    "                'supporting_methods': supporting_methods,\n",
    "                'support_count': support_count,\n",
    "                'confidence_level': 'High' if support_count >= 2 else 'Medium' if support_count == 1 else 'Low'\n",
    "            }, None\n",
    "            \n",
    "        except Exception as e:\n",
    "            return None, f\"Consensus analysis error: {str(e)}\"\n",
    "    \n",
    "    def get_current_price(self):\n",
    "        \"\"\"Get the most recent stock price\"\"\"\n",
    "        try:\n",
    "            if self.stock_data is not None:\n",
    "                return self.stock_data['Close'].iloc[-1]\n",
    "            else:\n",
    "                ticker_obj = yf.Ticker(self.ticker)\n",
    "                current_data = ticker_obj.history(period=\"1d\")\n",
    "                return current_data['Close'].iloc[-1] if not current_data.empty else None\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    def run_complete_analysis(self):\n",
    "        \"\"\"Run the complete prediction analysis\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"üöÄ COMPLETE PREDICTION ANALYSIS FOR {self.ticker}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Step 1: Download data\n",
    "        if not self.download_stock_data():\n",
    "            return None\n",
    "        \n",
    "        if not self.download_fundamentals():\n",
    "            return None\n",
    "        \n",
    "        # Step 2: Create correlation dataset\n",
    "        if self.create_correlation_dataset() is None:\n",
    "            return None\n",
    "        \n",
    "        # Step 3: Run all prediction methods\n",
    "        simple_result, simple_error = self.simple_price_prediction()\n",
    "        ml_result, ml_error = self.ml_ensemble_prediction()\n",
    "        dcf_result, dcf_error = self.dcf_fundamental_prediction()\n",
    "        \n",
    "        # Step 4: Analyze consensus\n",
    "        consensus_result, consensus_error = self.analyze_support_consensus(simple_result, ml_result, dcf_result)\n",
    "        \n",
    "        # Step 5: Get current price for comparison\n",
    "        current_market_price = self.get_current_price()\n",
    "        \n",
    "        # Step 6: Compile results\n",
    "        results = {\n",
    "            'ticker': self.ticker,\n",
    "            'analysis_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'current_market_price': current_market_price,\n",
    "            'stock_type': simple_result.get('stock_type', 'Unknown') if simple_result else 'Unknown',\n",
    "            'methods': {\n",
    "                'simple': simple_result,\n",
    "                'ml_ensemble': ml_result,\n",
    "                'dcf_fundamental': dcf_result\n",
    "            },\n",
    "            'consensus': consensus_result,\n",
    "            'errors': {\n",
    "                'simple': simple_error,\n",
    "                'ml_ensemble': ml_error,\n",
    "                'dcf_fundamental': dcf_error,\n",
    "                'consensus': consensus_error\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Step 7: Display results\n",
    "        self.display_results(results)\n",
    "        \n",
    "        # Step 8: Save results\n",
    "        self.save_results(results)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def display_results(self, results):\n",
    "        \"\"\"Display formatted results\"\"\"\n",
    "        print(f\"\\nüìä PREDICTION RESULTS FOR {results['ticker']}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        current_price = results.get('current_market_price')\n",
    "        if current_price:\n",
    "            print(f\"üí∞ Current Market Price: ${current_price:.2f}\")\n",
    "        \n",
    "        stock_type = results.get('stock_type', 'Unknown')\n",
    "        print(f\"üìà Stock Type: {stock_type}\")\n",
    "        \n",
    "        print(f\"\\nüéØ INDIVIDUAL METHOD PREDICTIONS:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        methods = results.get('methods', {})\n",
    "        \n",
    "        # Simple method\n",
    "        if methods.get('simple'):\n",
    "            simple = methods['simple']\n",
    "            change_pct = simple.get('price_change_pct', 0)\n",
    "            print(f\"üìä Simple Correlation: ${simple.get('predicted_price', 0):.2f} ({change_pct:+.1f}%)\")\n",
    "            print(f\"   Confidence: {simple.get('confidence', 'Unknown')}\")\n",
    "        \n",
    "        # ML Ensemble\n",
    "        if methods.get('ml_ensemble'):\n",
    "            ml = methods['ml_ensemble']\n",
    "            change_pct = ml.get('price_change_pct', 0)\n",
    "            print(f\"ü§ñ ML Ensemble: ${ml.get('predicted_price', 0):.2f} ({change_pct:+.1f}%)\")\n",
    "            print(f\"   Confidence: {ml.get('confidence', 'Unknown')}\")\n",
    "        \n",
    "        # DCF\n",
    "        if methods.get('dcf_fundamental'):\n",
    "            dcf = methods['dcf_fundamental']\n",
    "            change_pct = dcf.get('price_change_pct', 0)\n",
    "            print(f\"üíé DCF Fundamental: ${dcf.get('predicted_price', 0):.2f} ({change_pct:+.1f}%)\")\n",
    "            print(f\"   Confidence: {dcf.get('confidence', 'Unknown')}\")\n",
    "        \n",
    "        # Consensus\n",
    "        consensus = results.get('consensus')\n",
    "        if consensus:\n",
    "            print(f\"\\nüéØ CONSENSUS PREDICTION:\")\n",
    "            print(\"-\" * 30)\n",
    "            direction = consensus.get('consensus_prediction', 'Unknown')\n",
    "            supporting = ', '.join(consensus.get('supporting_methods', []))\n",
    "            confidence = consensus.get('confidence_level', 'Unknown')\n",
    "            \n",
    "            # Add emoji based on direction\n",
    "            if 'UP' in direction:\n",
    "                emoji = \"üìà\"\n",
    "            elif 'DOWN' in direction:\n",
    "                emoji = \"üìâ\"\n",
    "            else:\n",
    "                emoji = \"‚û°Ô∏è\"\n",
    "            \n",
    "            print(f\"{emoji} Direction: {direction}\")\n",
    "            print(f\"ü§ù Supporting Methods: {supporting if supporting else 'None'}\")\n",
    "            print(f\"üéØ Confidence Level: {confidence}\")\n",
    "        \n",
    "        # Errors (if any)\n",
    "        errors = results.get('errors', {})\n",
    "        error_count = sum(1 for error in errors.values() if error)\n",
    "        if error_count > 0:\n",
    "            print(f\"\\n‚ö†Ô∏è WARNINGS:\")\n",
    "            for method, error in errors.items():\n",
    "                if error:\n",
    "                    print(f\"   {method}: {error}\")\n",
    "    \n",
    "    def save_results(self, results):\n",
    "        \"\"\"Save results to files\"\"\"\n",
    "        try:\n",
    "            # Save detailed JSON results\n",
    "            json_file = f\"{self.results_folder}/{self.ticker}_prediction_results.json\"\n",
    "            with open(json_file, 'w') as f:\n",
    "                json.dump(results, f, indent=2, default=str)\n",
    "            \n",
    "            # Create summary CSV\n",
    "            summary_data = {\n",
    "                'Ticker': [self.ticker],\n",
    "                'Analysis_Date': [results.get('analysis_date')],\n",
    "                'Current_Price': [results.get('current_market_price')],\n",
    "                'Stock_Type': [results.get('stock_type')],\n",
    "                'Simple_Prediction': [results.get('methods', {}).get('simple', {}).get('predicted_price')],\n",
    "                'Simple_Change_%': [results.get('methods', {}).get('simple', {}).get('price_change_pct')],\n",
    "                'ML_Prediction': [results.get('methods', {}).get('ml_ensemble', {}).get('predicted_price')],\n",
    "                'ML_Change_%': [results.get('methods', {}).get('ml_ensemble', {}).get('price_change_pct')],\n",
    "                'DCF_Prediction': [results.get('methods', {}).get('dcf_fundamental', {}).get('predicted_price')],\n",
    "                'DCF_Change_%': [results.get('methods', {}).get('dcf_fundamental', {}).get('price_change_pct')],\n",
    "                'Consensus_Direction': [results.get('consensus', {}).get('consensus_prediction')],\n",
    "                'Supporting_Methods': [', '.join(results.get('consensus', {}).get('supporting_methods', []))],\n",
    "                'Confidence_Level': [results.get('consensus', {}).get('confidence_level')]\n",
    "            }\n",
    "            \n",
    "            summary_df = pd.DataFrame(summary_data)\n",
    "            csv_file = f\"{self.results_folder}/{self.ticker}_prediction_summary.csv\"\n",
    "            summary_df.to_csv(csv_file, index=False)\n",
    "            \n",
    "            print(f\"\\nüíæ RESULTS SAVED:\")\n",
    "            print(f\"   üìÑ Detailed: {json_file}\")\n",
    "            print(f\"   üìä Summary: {csv_file}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error saving results: {e}\")\n",
    "\n",
    "\n",
    "# USAGE FUNCTIONS\n",
    "def analyze_single_ticker(ticker):\n",
    "    \"\"\"Analyze a single ticker - main entry point\"\"\"\n",
    "    system = CompletePredictionSystem(ticker)\n",
    "    return system.run_complete_analysis()\n",
    "\n",
    "def analyze_multiple_tickers(tickers):\n",
    "    \"\"\"Analyze multiple tickers and create comparison matrix\"\"\"\n",
    "    print(f\"\\nüîÑ ANALYZING {len(tickers)} TICKERS...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    for i, ticker in enumerate(tickers, 1):\n",
    "        print(f\"\\n[{i}/{len(tickers)}] Processing {ticker}...\")\n",
    "        try:\n",
    "            system = CompletePredictionSystem(ticker)\n",
    "            result = system.run_complete_analysis()\n",
    "            if result:\n",
    "                all_results.append(result)\n",
    "                print(f\"‚úÖ {ticker} completed successfully\")\n",
    "            else:\n",
    "                print(f\"‚ùå {ticker} failed\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå {ticker} error: {e}\")\n",
    "    \n",
    "    # Create comparison matrix\n",
    "    if all_results:\n",
    "        create_comparison_matrix(all_results)\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "def create_comparison_matrix(results_list):\n",
    "    \"\"\"Create comparison matrix from multiple results\"\"\"\n",
    "    try:\n",
    "        print(f\"\\nüìä CREATING COMPARISON MATRIX...\")\n",
    "        \n",
    "        comparison_data = []\n",
    "        \n",
    "        for result in results_list:\n",
    "            ticker = result.get('ticker')\n",
    "            methods = result.get('methods', {})\n",
    "            consensus = result.get('consensus', {})\n",
    "            \n",
    "            row = {\n",
    "                'Ticker': ticker,\n",
    "                'Type': result.get('stock_type'),\n",
    "                'Current_Price': result.get('current_market_price'),\n",
    "                'Simple_Prediction': methods.get('simple', {}).get('predicted_price'),\n",
    "                'Simple_Change_%': methods.get('simple', {}).get('price_change_pct'),\n",
    "                'ML_Prediction': methods.get('ml_ensemble', {}).get('predicted_price'),\n",
    "                'ML_Change_%': methods.get('ml_ensemble', {}).get('price_change_pct'),\n",
    "                'DCF_Prediction': methods.get('dcf_fundamental', {}).get('predicted_price'),\n",
    "                'DCF_Change_%': methods.get('dcf_fundamental', {}).get('price_change_pct'),\n",
    "                'Consensus_Direction': consensus.get('consensus_prediction'),\n",
    "                'Supporting_Methods': ', '.join(consensus.get('supporting_methods', [])),\n",
    "                'Confidence': consensus.get('confidence_level')\n",
    "            }\n",
    "            comparison_data.append(row)\n",
    "        \n",
    "        # Create DataFrame\n",
    "        comparison_df = pd.DataFrame(comparison_data)\n",
    "        \n",
    "        # Save comparison matrix\n",
    "        os.makedirs('results', exist_ok=True)\n",
    "        matrix_file = 'results/multi_ticker_comparison_matrix.csv'\n",
    "        comparison_df.to_csv(matrix_file, index=False)\n",
    "        \n",
    "        # Display summary\n",
    "        print(f\"\\nüìã COMPARISON MATRIX SUMMARY:\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Total tickers analyzed: {len(comparison_df)}\")\n",
    "        \n",
    "        # Direction distribution\n",
    "        if 'Consensus_Direction' in comparison_df.columns:\n",
    "            direction_counts = comparison_df['Consensus_Direction'].str.replace(r'\\+', '', regex=True).value_counts()\n",
    "            print(f\"\\nDirection Distribution:\")\n",
    "            for direction, count in direction_counts.items():\n",
    "                if pd.notna(direction):\n",
    "                    emoji = \"üìà\" if direction == \"UP\" else \"üìâ\" if direction == \"DOWN\" else \"‚û°Ô∏è\"\n",
    "                    print(f\"  {emoji} {direction}: {count} stocks\")\n",
    "        \n",
    "        # Confidence distribution\n",
    "        if 'Confidence' in comparison_df.columns:\n",
    "            confidence_counts = comparison_df['Confidence'].value_counts()\n",
    "            print(f\"\\nConfidence Distribution:\")\n",
    "            for confidence, count in confidence_counts.items():\n",
    "                if pd.notna(confidence):\n",
    "                    print(f\"  {confidence}: {count} stocks\")\n",
    "        \n",
    "        # Top opportunities\n",
    "        if 'Simple_Change_%' in comparison_df.columns:\n",
    "            positive_changes = comparison_df[comparison_df['Simple_Change_%'] > 0].sort_values('Simple_Change_%', ascending=False)\n",
    "            if len(positive_changes) > 0:\n",
    "                print(f\"\\nüöÄ TOP OPPORTUNITIES (Simple Method):\")\n",
    "                for _, row in positive_changes.head(5).iterrows():\n",
    "                    print(f\"  {row['Ticker']}: {row['Simple_Change_%']:+.1f}% ({row['Consensus_Direction']})\")\n",
    "        \n",
    "        print(f\"\\nüíæ Comparison matrix saved to: {matrix_file}\")\n",
    "        \n",
    "        return comparison_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error creating comparison matrix: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# MAIN EXECUTION EXAMPLES\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üéØ COMPLETE STOCK PREDICTION SYSTEM\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Example 1: Single ticker analysis\n",
    "    print(\"\\nüìä EXAMPLE 1: Single Ticker Analysis\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Uncomment to run single ticker analysis\n",
    "    # ticker = \"JPM\"  # Change to your desired ticker\n",
    "    # result = analyze_single_ticker(ticker)\n",
    "    \n",
    "    # Example 2: Multiple ticker analysis\n",
    "    print(\"\\nüìä EXAMPLE 2: Multiple Ticker Analysis\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Uncomment to run multiple ticker analysis\n",
    "    # tickers = [\"JPM\", \"BAC\", \"WFC\", \"C\", \"GS\"]  # Change to your desired tickers\n",
    "    # results = analyze_multiple_tickers(tickers)\n",
    "    \n",
    "    print(\"\\nüí° USAGE INSTRUCTIONS:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\"1. For single ticker: analyze_single_ticker('TICKER')\")\n",
    "    print(\"2. For multiple tickers: analyze_multiple_tickers(['TICKER1', 'TICKER2', ...])\")\n",
    "    print(\"3. Results are automatically saved to 'results/' folder\")\n",
    "    print(\"4. Requires internet connection for yfinance data download\")\n",
    "    print(\"5. Optional: Install scikit-learn and xgboost for ML methods\")\n",
    "    \n",
    "    print(f\"\\nüìÅ FOLDER STRUCTURE:\")\n",
    "    print(\"‚îú‚îÄ‚îÄ data/              # Stock price data (CSV)\")\n",
    "    print(\"‚îú‚îÄ‚îÄ fundamentals/      # Quarterly fundamental data (JSON)\")\n",
    "    print(\"‚îî‚îÄ‚îÄ results/           # Prediction results and summaries\")\n",
    "\n",
    "\n",
    "def quick_prediction(ticker):\n",
    "    \"\"\"Quick prediction function - simplified interface\"\"\"\n",
    "    print(f\"üöÄ Quick Prediction for {ticker.upper()}\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    try:\n",
    "        result = analyze_single_ticker(ticker)\n",
    "        \n",
    "        if result and result.get('consensus'):\n",
    "            consensus = result['consensus']\n",
    "            direction = consensus.get('consensus_prediction', 'Unknown')\n",
    "            confidence = consensus.get('confidence_level', 'Unknown')\n",
    "            supporting = ', '.join(consensus.get('supporting_methods', []))\n",
    "            \n",
    "            # Simple summary\n",
    "            print(f\"\\nüéØ QUICK SUMMARY:\")\n",
    "            print(f\"Direction: {direction}\")\n",
    "            print(f\"Confidence: {confidence}\")\n",
    "            print(f\"Support: {supporting if supporting else 'None'}\")\n",
    "            \n",
    "            return direction, confidence, supporting\n",
    "        else:\n",
    "            print(\"‚ùå Unable to generate prediction\")\n",
    "            return None, None, None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "\n",
    "# Advanced usage examples\n",
    "def batch_analyze_from_file(filename):\n",
    "    \"\"\"Analyze tickers from a text file (one ticker per line)\"\"\"\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            tickers = [line.strip().upper() for line in f if line.strip()]\n",
    "        \n",
    "        print(f\"üìÇ Loaded {len(tickers)} tickers from {filename}\")\n",
    "        return analyze_multiple_tickers(tickers)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading file: {e}\")\n",
    "        return None\n",
    "\n",
    "def update_existing_analysis(ticker):\n",
    "    \"\"\"Update analysis for a ticker with fresh data\"\"\"\n",
    "    print(f\"üîÑ Updating analysis for {ticker}...\")\n",
    "    \n",
    "    # This will automatically download fresh data\n",
    "    return analyze_single_ticker(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc37f2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Quick Prediction for GOOGL\n",
      "========================================\n",
      "üéØ Initializing Complete Prediction System for GOOGL\n",
      "\n",
      "============================================================\n",
      "üöÄ COMPLETE PREDICTION ANALYSIS FOR GOOGL\n",
      "============================================================\n",
      "üìä Downloading stock data for GOOGL...\n",
      "‚úÖ Stock data saved to data/GOOGL_stock_data.csv\n",
      "üìà Downloading fundamentals for GOOGL...\n",
      "‚úÖ Fundamentals saved: 5 quarters available\n",
      "üîó Creating correlation dataset...\n",
      "‚ùå Error creating correlation dataset: Invalid comparison between dtype=datetime64[ns, America/New_York] and Timestamp\n",
      "‚ùå Unable to generate prediction\n",
      "Prediction: None | Confidence: None\n"
     ]
    }
   ],
   "source": [
    "direction, confidence, support = quick_prediction(\"GOOGL\")\n",
    "print(f\"Prediction: {direction} | Confidence: {confidence}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
